import os
import re
import pandas as pd
from typing import TypedDict, Annotated, List
from dotenv import load_dotenv

from langchain_core.messages import BaseMessage, HumanMessage, ToolMessage
from langchain_core.prompts import ChatPromptTemplate
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages

from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent

from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.docstore.document import Document
from langchain.prompts import ChatPromptTemplate
from langchain_core.exceptions import OutputParserException

# ====== í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ======
load_dotenv()
API_KEY = os.getenv("API_KEY")

# ====== LLM ë° Embeddings ì„¤ì • ======
llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", google_api_key=API_KEY)
embeddings = GoogleGenerativeAIEmbeddings(
    model="models/text-embedding-004", google_api_key=API_KEY
)


# ====== ë°ì´í„° ì¤€ë¹„ ë° Pandas Agent ìƒì„± ======
df = pd.read_excel("public/ìµœì¢… ë°ì´í„°ì…‹.xlsx")
df_storetype_sales_competition = pd.read_csv(
    "public/ìƒê¶Œ_ì—…ì¢…ë³„_ë§¤ì¶œ_ê²½ìŸê°•ë„_ë¶„ì„ê²°ê³¼ë¦¬ìŠ¤íŠ¸.csv"
)
df_area_sales_competition = pd.read_csv(
    "public/ìƒê¶Œë³„_ë§¤ì¶œ_ê²½ìŸê°•ë„_ë¶„ì„ê²°ê³¼ë¦¬ìŠ¤íŠ¸.csv"
)
df_storetype_features = pd.read_csv("public/ìƒê¶Œ_ì—…ì¢…ë³„_íŠ¹ì§•ë¶„ì„ê²°ê³¼_ë¦¬ìŠ¤íŠ¸.csv")
df_area_features = pd.read_csv("public/ìƒê¶Œë³„_íŠ¹ì§•ë¶„ì„ê²°ê³¼_ë¦¬ìŠ¤íŠ¸.csv")

pandas_agent = create_pandas_dataframe_agent(
    llm=llm,
    df=[
        df,
        df_storetype_sales_competition,
        df_area_sales_competition,
        df_storetype_features,
        df_area_features,
    ],
    verbose=True,
    allow_dangerous_code=True,
    agent_executor_kwargs={"handle_parsing_errors": True},
)


# === RAG ì´ˆê¸°í™” í•¨ìˆ˜ ===
def initialize_rag(
    embeddings,
    pdf_folder: str = "public/rag_documents",
    persist_path: str = "public/vectorstores",
):
    os.makedirs(persist_path, exist_ok=True)

    if os.path.exists(os.path.join(persist_path, "index.faiss")):
        print("Loading existing FAISS vectorstore from disk...")
        vectorstore = FAISS.load_local(
            persist_path, embeddings, allow_dangerous_deserialization=True
        )
    else:
        print("Creating new FAISS vectorstore from PDF documents...")

        all_docs: List[Document] = []
        for file in os.listdir(pdf_folder):
            if file.endswith(".pdf"):
                loader = PyPDFLoader(os.path.join(pdf_folder, file))
                docs = loader.load()
                all_docs.extend(docs)

        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000, chunk_overlap=200
        )
        split_docs = text_splitter.split_documents(all_docs)

        vectorstore = FAISS.from_documents(split_docs, embeddings)
        vectorstore.save_local(persist_path)
        print("Complteted creating and saving FAISS vectorstore.")

    retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
    return retriever


retriever = initialize_rag(embeddings)

marketing_prompt = ChatPromptTemplate.from_template(
    """
ë‹¹ì‹ ì€ ìµœê³ ì˜ ë§ˆì¼€íŒ… ì „ëµê°€ì…ë‹ˆë‹¤.
ë‹¹ì‹ ì€ ì„±ë™êµ¬ì˜ ì‹ë‹¹, ì¹´í˜ ê°€ë§¹ì ë“¤ì— ëŒ€í•´ ë§ˆì¼€íŒ… ì „ëµì„ ìˆ˜ë¦½í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ íš¨ê³¼ì ì¸ ë§ˆì¼€íŒ… ì „ëµì„ ì œì•ˆí•˜ì„¸ìš”. 
"ë°ì´í„° ë¶„ì„"ì´ ìˆë‹¤ë©´ ë°˜ë“œì‹œ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ê³  ì°¸ê³  ìë£Œë¥¼ ìµœëŒ€í•œ í™œìš©í•˜ì„¸ìš”. 
ì œì•ˆí•œ ë§ˆì¼€íŒ… ì „ëµì—ëŠ” ê·¼ê±°ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”. 

[ë°ì´í„° ë¶„ì„]
{analysis_result}

[ì°¸ê³  ìë£Œ]
{context}

[ì§ˆë¬¸]
{question}

[ì „ëµ ì œì•ˆ]
"""
)


def rag_chain(query: str, analysis_result: str) -> str:
    """RAG ê¸°ë°˜ ë§ˆì¼€íŒ… ì „ëµ ìƒì„±"""
    docs = retriever.invoke(query)
    context = "\n".join([d.page_content for d in docs])
    prompt_text = marketing_prompt.format_prompt(
        context=context, question=query, analysis_result=analysis_result
    ).to_string()

    return llm.invoke(prompt_text)


# ====== State ì •ì˜ ======
class State(TypedDict):
    query: str
    analysis_result: str
    marketing_strategy: str
    chain_both: bool
    next_node: str
    final_answer: str


# ====== Node ì •ì˜ ======
def data_analyst_node(state: State) -> State:
    """
    ë°ì´í„° ë¶„ì„ ë…¸ë“œ
    - ì—´ìë¦¬ì˜ ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„ì„ ìˆ˜í–‰í•  ê²ƒ (ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸ ì˜ˆì‹œ: 01EDD97C21 ë“±)
    - í•„ìš”í•œ ë°ì´í„°í”„ë ˆì„ì„ ì„ íƒí•˜ê³  ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ì˜ ì˜ë„ë¥¼ íŒŒì•…í•˜ì—¬ ë¶„ì„ ìˆ˜í–‰
    - ê²°ê³¼ë¥¼ ToolMessageë¡œ ë°˜í™˜
    - í•„ìš”ì‹œ ì—¬ëŸ¬ ë°ì´í„°í”„ë ˆì„ì„ ë¶„ì„ í›„ ê²°ê³¼ë¥¼ ì •ë¦¬
    """
    query = state["query"]
    prompt = f"query: {query}\në‹¹ì‹ ì€ ë°ì´í„° ë¶„ì„ê°€ ì…ë‹ˆë‹¤. ì‚¬ìš©ì ì¿¼ë¦¬ì— ë§ê²Œ ì£¼ì–´ì§„ ë°ì´í„°í”„ë ˆì„ë“¤ì„ ë¶„ì„í•˜ì—¬ ë§ˆì¼€íŒ… ì „ëµ ìˆ˜ë¦½ê°€ì—ê²Œ ë¶„ì„ ê²°ê³¼ ë° ì¸ì‚¬ì´íŠ¸ë¥¼ ë„˜ê²¨ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤. ì „ëµ ì œì•ˆì€ ë‹¹ì‹ ì˜ ì—­í• ì´ ì•„ë‹™ë‹ˆë‹¤. ë°ì´í„° ë¶„ì„ë§Œ ì§„í–‰í•˜ì„¸ìš”. "
    try:
        analysis_result = pandas_agent.invoke(prompt)
        response_content = analysis_result["output"]
    except (OutputParserException, ValueError) as e:
        error_message = str(e)

        match = re.search(
            r"Could not parse LLM output: `(.*)`", error_message, re.DOTALL
        )

        if match:
            response_content = match.group(1).strip()
        else:
            response_content = (
                "ì—ì´ì „íŠ¸ íŒŒì‹± ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìœ¼ë‚˜ ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            )
    state["analysis_result"] = response_content
    return state


def marketing_strategist_node(state: State) -> State:
    """
    ë§ˆì¼€íŒ… ì „ëµ ë…¸ë“œ
    - RAG ê¸°ë°˜ ì „ëµ ìƒì„±
    - ë°˜ë“œì‹œ ê·¼ê±°ê°€ í¬í•¨ëœ ì „ëµ ì œì•ˆ
    - ì–´ë–¤ ë¬¸ì„œì˜ ì–´ë–¤ ë¶€ë¶„ì„ ì°¸ê³ í–ˆëŠ”ì§€ í¬í•¨
    """
    query = state["query"]
    prompt = f"query: {query}\në‹¹ì‹ ì€ ìµœê³ ì˜ ë§ˆì¼€íŒ… ì „ëµê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ íš¨ê³¼ì ì¸ ë§ˆì¼€íŒ… ì „ëµì„ ì œì•ˆí•˜ì„¸ìš”. ë°ì´í„° ë¶„ì„ê°’ì´ ìˆë‹¤ë©´ ë°˜ë“œì‹œ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ê³  ì°¸ê³  ìë£Œë¥¼ ìµœëŒ€í•œ í™œìš©í•˜ì„¸ìš”. ì œì•ˆí•œ ë§ˆì¼€íŒ… ì „ëµì—ëŠ” ê·¼ê±°ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”."
    analysis_result = state.get("analysis_result", "")
    strategy = rag_chain(prompt, analysis_result).content
    state["marketing_strategy"] = strategy
    return state


def supervisor_node(state: State) -> State:
    """
    ìŠˆí¼ë°”ì´ì € ë…¸ë“œ
    - ì‚¬ìš©ì ì§ˆë¬¸ ë¶„ì„ í›„ ë‹¤ìŒì— ì‹¤í–‰í•  ë…¸ë“œë¥¼ ê²°ì •
    - ê·¸ë˜í”„ íë¦„ ì œì–´
    """
    query = state["query"]
    llm_prompt = """
ë‹¹ì‹ ì€ ì„±ë™êµ¬ ê°€ë§¹ì  ë§ˆì¼€íŒ… ì»¨ì„¤íŒ… ë° ë°ì´í„° ë¶„ì„ AIë“¤ì˜ ì´ê´„ì…ë‹ˆë‹¤.
ê°€ë§¹ì ì£¼ë“¤ì˜ ìš”êµ¬ì— ë§ëŠ” ìµœì ì˜ ì „ë¬¸ê°€ë¥¼ ë°°ì •í•˜ì„¸ìš”. 
ì‚¬ìš©ì ì§ˆë¬¸ì„ ë³´ê³  í•„ìš”í•œ ì „ë¬¸ê°€ë¥¼ ê²°ì •í•˜ì„¸ìš”:
- ë°ì´í„° ë¶„ì„ í•„ìš” â†’ data_analyst
    - ì„±ë™êµ¬ ì „ì²´ ê°€ë§¹ì  ë°ì´í„°(ë§¤ì¶œ, ê³ ê° ì •ë³´ ë“±), ìƒê¶Œ ë° ì—…ì¢… ë³„ ê²½ìŸ ê°•ë„ì™€ íŠ¹ì§• ë¶„ì„ ë°ì´í„° ë³´ìœ  ì¤‘
- ë§ˆì¼€íŒ… ì „ëµ í•„ìš” â†’ marketing_strategist
- ë‘˜ ë‹¤ í•„ìš” â†’ both
- ë‘˜ ë‹¤ í•„ìš” ì—†ìŒ â†’ FINISH
ì¶œë ¥ì€ ë°˜ë“œì‹œ ë‹¤ìŒ ì¤‘ í•˜ë‚˜: data_analyst, marketing_strategist, both, FINISH
"""
    decision_input = f"{llm_prompt}\n[ì§ˆë¬¸]\n{query}"
    decision = llm.invoke(decision_input).content.strip()

    if decision not in ["data_analyst", "marketing_strategist", "both", "FINISH"]:
        decision = "FINISH"

    print(f"DEBUG: Supervisor íŒë‹¨ -> {decision}")

    if decision == "data_analyst":
        state["next_node"] = "data_analyst"
    elif decision == "marketing_strategist":
        state["next_node"] = "marketing_strategist"
    elif decision == "both":
        state["next_node"] = "data_analyst"
        state["chain_both"] = True
    elif decision == "FINISH":
        analysis = state.get("analysis_result", "")
        marketing = state.get("marketing_strategy", "")

    return state


def summerize_final_answer_node(state: State) -> dict:
    """
    ìµœì¢… ìš”ì•½ ë‹µë³€ ìƒì„± ë…¸ë“œ
    - ë°ì´í„° ë¶„ì„ ê²°ê³¼ì™€ ë§ˆì¼€íŒ… ì „ëµì„ ì¢…í•©í•˜ì—¬ ìµœì¢… ë‹µë³€ ìƒì„±
    """
    query = state["query"]
    analysis_result = state.get("analysis_result", "")
    marketing_strategy = state.get("marketing_strategy", "")

    if analysis_result or marketing_strategy:
        summary_prompt = f"""
ë‹¹ì‹ ì€ ê°€ë§¹ì  ì»¨ì„¤íŒ… AIëŒ ì¤‘ ê²°ê³¼ ì •ë¦¬ ì—­í• ì…ë‹ˆë‹¤.
ë‹¤ìŒì€ ì§€ê¸ˆê¹Œì§€ ìˆ˜í–‰ëœ ë¶„ì„ ë° ì „ëµ ì œì•ˆ ê²°ê³¼ì…ë‹ˆë‹¤.
ì‚¬ìš©ì ì§ˆì˜ì— ë§ëŠ” ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”.
ì´ë¥¼ ì°¸ê³ í•˜ì—¬ í•µì‹¬ë§Œ ìš”ì•½í•´ ì‚¬ìš©ìì—ê²Œ í•œëˆˆì— ë³´ì´ê²Œ ì •ë¦¬í•˜ì„¸ìš”.
ë°ì´í„° ë¶„ì„ ë‚´ìš©ê³¼ ë§ˆì¼€íŒ… ì „ëµì˜ ê·¼ê±°ë¥¼ ë°˜ë“œì‹œ ëª…ì‹œí•´ì•¼ í•©ë‹ˆë‹¤.

[ì‚¬ìš©ì ì§ˆë¬¸]
{query}

[ë°ì´í„° ë¶„ì„ ê²°ê³¼]
{analysis_result}

[ë§ˆì¼€íŒ… ì „ëµ ì œì•ˆ]
{marketing_strategy}

[ìš”ì•½ ë° ìµœì¢… ì œì•ˆ]
"""
        final_answer = llm.invoke(summary_prompt).content
        state["final_answer"] = final_answer
    return state


# ====== Graph ì„¤ì • ======
workflow = StateGraph(State)

workflow.add_node("supervisor", supervisor_node)
workflow.add_node("data_analyst", data_analyst_node)
workflow.add_node("marketing_strategist", marketing_strategist_node)
workflow.add_node("final_summarizer", summerize_final_answer_node)

workflow.add_edge(START, "supervisor")

workflow.add_conditional_edges(
    "supervisor",
    lambda state: state["next_node"],
    {
        "data_analyst": "data_analyst",
        "marketing_strategist": "marketing_strategist",
        "both": "data_analyst",
        "FINISH": "final_summarizer",
    },
)

workflow.add_conditional_edges(
    "data_analyst",
    lambda state: "marketing_strategist" if state.get("chain_both") else "FINISH",
    {
        "marketing_strategist": "marketing_strategist",
        "FINISH": "final_summarizer",
    },
)

workflow.add_edge("marketing_strategist", "final_summarizer")
workflow.add_edge("final_summarizer", END)

app = workflow.compile()

# ====== Main Loop ======
if __name__ == "__main__":
    print("\nì±„íŒ… ì‹œì‘ (exit/q ì…ë ¥ ì‹œ ì¢…ë£Œ)")
    while True:
        user_input = input("\n> ì‚¬ìš©ì ì§ˆë¬¸: ")
        if user_input.lower() in ["exit", "q"]:
            break

        state = {
            "query": user_input,
            "analysis_result": "",
            "marketing_strategy": "",
            "chain_both": False,
            "next_node": "",
            "final_answer": "",
        }

        result = app.invoke(state)

        # ====== ê²°ê³¼ ì¶œë ¥ ======
        print("\n" + "=" * 60)
        print("ğŸ“Š [ë°ì´í„° ë¶„ì„ ê²°ê³¼]")
        print(result.get("analysis_result", "(ì—†ìŒ)"))

        print("\nğŸ’¡ [ë§ˆì¼€íŒ… ì „ëµ ì œì•ˆ]")
        print(result.get("marketing_strategy", "(ì—†ìŒ)"))

        print("\nğŸ§­ [ìµœì¢… ìš”ì•½ ë‹µë³€]")
        print(result.get("final_answer", "(ì—†ìŒ)"))
        print("=" * 60)
